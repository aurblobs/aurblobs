#!/usr/bin/env python3
import datetime
import json
import os
import sys
from argparse import ArgumentParser
from tempfile import TemporaryDirectory

import docker, docker.errors
import git
import gnupg
import xdg
import requests
from pidfile import PIDFile
from voluptuous import Schema, Length, All, Required

__PROJECT__ = 'aur-repositor'
__VERSION__ = '0.1'


CONFIG_SCHEMA = Schema({
    Required('version'): 1,
    Required('repository'): Schema({
        Required('name'): str,
        Required('root'): str
    }),
    Required('pkgs'): [str]
})
STATE_SCHEMA = Schema({
    'version': 1,
    'pkgs': Schema({str: All(str, Length(40))})
})

CONFIG_DIR = os.path.join(xdg.XDG_CONFIG_HOME, __PROJECT__)
CACHE_DIR = os.path.join(xdg.XDG_CACHE_HOME, __PROJECT__)


class UnknownPackageException(BaseException):
    pass


class AurRepositor:
    def __init__(self, repository):
        # create empty schema
        self.config = {
            'version': 1,
            'repository': None,
            'pkgs': []
        }

        self.state = {
            'version': 1,
            'pkgs': {}
        }

        self.config_file = os.path.join(CONFIG_DIR, '{0}.json'.format(repository))
        self.state_file = os.path.join(CACHE_DIR, '{0}.json'.format(repository))

        # load existing config and state
        self.load()

    def repo_init(self, root, name, mail):
        # prevent collision
        if os.path.exists(self.config_file):
            return

        # create repository root
        os.makedirs(root)
        self.config['repository'] = {
            'name': name,
            'root': root
        }

        # create repository signing key
        with TemporaryDirectory() as basedir:
            gpg = gnupg.GPG(homedir=basedir)
            input_data = gpg.gen_key_input(
                key_type='eddsa', key_length=521, key_curve='Ed25519',
                key_usage='sign', expire_date=0, name_email=mail,
                name_real='{0} repository key'.format(name),
                testing=True  # don't protect the key
            )
            key = gpg.gen_key(input_data)

            # copy public key to repository root
            with open(os.path.join(self.config['repository']['root'], '{0}.gpg'.format(name)), 'w') as handle:
                handle.write(gpg.export_keys(key))

            # copy private key to config root
            with open(os.path.join(CONFIG_DIR, '{0}.gpg'.format(name)), 'w') as handle:
                handle.write(gpg.export_keys(key, True))

        # persist configuration
        self.save()

    @staticmethod
    def repo_list():
        for fn in os.listdir(CONFIG_DIR):
            if fn.endswith('.json'):
                yield fn

    def load(self):
        # configuration
        try:
            with open(self.config_file) as handle:
                self.config = CONFIG_SCHEMA(json.load(handle))
        except FileNotFoundError:
            pass

        # state
        try:
            with open(self.state_file) as handle:
                self.state = STATE_SCHEMA(json.load(handle))
        except FileNotFoundError:
            pass

    def save(self):
        # configuration
        with open(self.config_file, 'w') as handle:
            print(json.dumps(self.config, indent=2))
            json.dump(self.config, handle)

        # state
        with open(self.state_file, 'w') as handle:
            json.dump(self.state, handle)

    def pkg_list(self):
        # TODO: track state + config packets and give them separate states
        for pkgname in self.config['pkgs']:
            yield pkgname

    def pkg_add(self, pkgname):
        # check if pkg exists
        response = requests.head(self.pkg_url(pkgname))
        if response.status_code == 404:
            raise UnknownPackageException()

        # persist pkg to config
        # TODO: set?
        if pkgname not in self.config['pkgs']:
            self.config['pkgs'].append(pkgname)
        self.save()

    def pkg_rm(self, pkgname):
        # remove pkg from config and state if exists
        if pkgname in self.config['pkgs']:
            del self.config['pkgs'][pkgname]
        if pkgname in self.state['pkgs']:
            del self.state['pkgs'][pkgname]

        # persist change
        self.save()

        # remove pkg from repository
        # TODO: repo-remove call

    @staticmethod
    def pkg_remote(pkgname):
        return 'https://aur.archlinux.org/{0}.git'.format(pkgname)

    @staticmethod
    def pkg_url(pkgname):
        return 'https://aur.archlinux.org/packages/{0}/'.format(pkgname)

    def pkg_is_new(self, pkgname, pkgversion):
        # this is a crude way, but is there a more beautiful way?
        # TODO: evaluate pkgver() functions if exists
        if pkgname not in self.state['pkgs']:
            print('{0} is new!'.format(pkgname))
            return True
        print('{0} local={1}, remote={2}'.format(pkgname, self.state['pkgs'][pkgname], pkgversion))
        return self.state['pkgs'][pkgname] != pkgversion

    def pkg_check(self, pkgname, force=False):
        with TemporaryDirectory(prefix=__PROJECT__, suffix=pkgname) as basedir:
            pkgroot = os.path.join(basedir, '{}.git'.format(pkgname))
            pkgrepo = git.Repo.clone_from(
                self.pkg_remote(pkgname), pkgroot
            )
            if force or self.pkg_is_new(pkgname, str(pkgrepo.head.commit)):
                self.pkg_build(pkgname, str(pkgrepo.head.commit), pkgroot)

    def pkg_build(self, pkgname, pkgversion, pkgroot):
        gpg_privkey = os.path.join(
            CONFIG_DIR, '{0}.gpg'.format(self.config['repository']['name']))
        timestamp = '{:%H-%M}'.format(datetime.datetime.now())

        client = docker.from_env()

        try:
            client.images.get('aur-repositor-build')
        except docker.errors.ImageNotFound:
            self.docker_prepare()

        print("Building {}...".format(pkgname))
        # remove=True only removed for debugging purposes in this early stage.
        container = client.containers.run(
            image='aur-repositor-build',
            name='repositor_{}_{}'.format(pkgname, timestamp),
            detach=True,
            environment={
                "REPO_NAME": self.config['repository']['name'],
                "USER_ID": os.getuid()
            },
            volumes={
                pkgroot: {'bind': '/pkg', 'mode': 'rw'},
                self.config['repository']['root']: {'bind': '/repo', 'mode': 'rw'},
                gpg_privkey: {'bind': '/privkey.gpg', 'mode': 'ro'}
            }
        )
        for line in container.logs(stream=True):
            print(line.decode())
        self.state['pkgs'][pkgname] = pkgversion
        self.save()

    def update(self, force):
        # Update container before starting a update-all run
        AurRepositor.docker_prepare()
        for pkgname in self.pkg_list():
            self.pkg_check(pkgname, force)

    @staticmethod
    def docker_prepare():
        client = docker.from_env()
        client.images.build(path='docker/', tag='aur-repositor-build')


if __name__ == '__main__':
    if not os.path.exists(CONFIG_DIR):
        os.makedirs(CONFIG_DIR)
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)

    argparser = ArgumentParser()
    subparser = argparser.add_subparsers()

    # Manage Repositories
    repo_init_parser = subparser.add_parser('init', help='Initialize a repository')
    repo_init_parser.set_defaults(mode='init')
    # TODO: forbid [local, core, extra, community multilib, ]
    repo_init_parser.add_argument('-r', '--repository', dest='repository', required=True)
    repo_init_parser.add_argument('--root', required=True, help='Path to the repository root')
    repo_init_parser.add_argument('--mail', required=True, help='Mail address for the Signing Key')

    repo_list_parser = subparser.add_parser('rlist', help='List available repositories')
    repo_list_parser.set_defaults(mode='rlist')

    repo_update_parser = subparser.add_parser(
        'update', aliases=['up'], help='Update all packages in repository')
    repo_update_parser.set_defaults(mode='update')
    repo_update_parser.add_argument('-r', '--repository', dest='repository', required=True)
    repo_update_parser.add_argument('-f', '--force', action='store_true')

    # Manage Packages
    pkg_add_parser = subparser.add_parser('add', help='Add a new package')
    pkg_add_parser.set_defaults(mode='add')
    pkg_add_parser.add_argument('pkg', help='AUR packet name')
    pkg_add_parser.add_argument('-r', '--repository', dest='repository', required=True)

    pkg_list_parser = subparser.add_parser('list', help='Show configured packages')
    pkg_list_parser.set_defaults(mode='list')
    pkg_list_parser.add_argument('-r', '--repository', dest='repository', required=True)

    pkg_rm_parser = subparser.add_parser('rm', help='Remove a package')
    pkg_rm_parser.set_defaults(mode='rm')
    pkg_rm_parser.add_argument('pkg', help='AUR packet name')
    pkg_rm_parser.add_argument('-r', '--repository', dest='repository', required=True)

    args = argparser.parse_args()

    # read-only operations
    if 'mode' not in args:
        sys.exit(0)
    elif args.mode == 'rlist':
        for repo in AurRepositor.repo_list():
            print(''.join(repo.split('.')[0:-1]))
        sys.exit(0)

    # read/write operations
    with PIDFile(os.path.join(CONFIG_DIR, '{}.pid'.format(args.repository))):
        repositor = AurRepositor(args.repository)

        if args.mode == 'add':
            repositor.pkg_add(args.pkg)

        elif args.mode == 'rm':
            repositor.pkg_rm(args.pkg)

        elif args.mode == 'list':
            for pkg, version in repositor.pkg_list():
                print(pkg, version)

        elif args.mode == 'init':
            repositor.repo_init(args.root, args.repository, args.mail)

        elif args.mode == 'update':
            repositor.update(args.force)
